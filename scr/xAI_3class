"""
XAI script for 3-class classification (Normal / Monolateral / Bilateral).

Reimplements the logic of:
    "XAI con pesi Tre classi.ipynb"

Main steps:
- Load Agati features table and split into train/val/test (stratified by Class)
- Build a CustomDataset that returns:
    - transformed image (for model input)
    - additional features
    - integer labels (0,1,2)
    - original resized image (for visualization)
- Rebuild the same CombinedModel (CNN + MLP) used for 3-class training
- Load pretrained weights (best_model_three.pth)
- Evaluate on test set and compute confusion matrix
- Run Integrated Gradients (Captum) to obtain:
    - image attributions
    - feature attributions
- Save attributions to .npy and optionally visualize one example

NOTE:
- This script assumes you have `models_common.py` in the same project,
  defining device, composer, set_global_seed, ModifiedResNet18, MLPModule,
  CombinedModel, etc.
"""

import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image

from captum.attr import IntegratedGradients

from models_common import (
    device,
    composer,           # image transforms (Resize+Gray+Normalize)
    set_global_seed,
    ModifiedResNet18,
    MLPModule,
    CombinedModel,
)

# --------------------------------------------------
# Paths (ADJUST THESE FOR YOUR ENVIRONMENT)
# --------------------------------------------------

DATA_DIR = "/content/drive/MyDrive/AI in healthcare/Laryngeal paralysis/Spain Dataset/Trials"
FEATURES_XLSX = os.path.join(DATA_DIR, "Agati features.xlsx")
WEIGHTS_PATH = "/content/drive/MyDrive/AI in healthcare/Laryngeal paralysis/Weights/best_model_three.pth"
ATTRIBUTIONS_OUT = "/content/drive/MyDrive/AI in healthcare/Laryngeal paralysis/Weights/attributions.npy"


# --------------------------------------------------
# Dataset for XAI (returns also original image)
# --------------------------------------------------

class XAIDataset(Dataset):
    """
    Dataset that:
    - loads image from 'Path' in the features DataFrame
    - returns:
        * 'image'  : transformed image tensor (for model)
        * 'additional_features': feature vector (float32)
        * 'labels' : integer class label (0,1,2)
        * 'original': resized image tensor (C,H,W) for visualization
    """

    def __init__(self, subjects, features_dataframe, transform=None):
        self.subjects = subjects
        self.features_dataframe = features_dataframe
        self.transform = transform
        self.resize = transforms.Resize((250, 250))
        self.to_tensor = transforms.ToTensor()

    def __len__(self):
        return len(self.features_dataframe)

    def __getitem__(self, idx):
        # Name of the trial
        name = self.subjects[idx]

        # Locate row
        row = self.features_dataframe.loc[self.features_dataframe["Name"] == name].iloc[0]

        # Load image
        image_path = row["Path"]
        image = Image.open(image_path)

        # Original resized image (for visualization)
        resized = self.resize(image)
        original_tensor = self.to_tensor(resized)

        # Additional features: columns between 'Name' and 'Class'
        name_idx = list(self.features_dataframe.columns).index("Name")
        class_idx = list(self.features_dataframe.columns).index("Class")
        feat_vals = row.iloc[name_idx + 1:class_idx].values.astype("float32")
        additional_features = torch.tensor(feat_vals, dtype=torch.float32)

        # Label as integer (0,1,2)
        label = int(row["Class"])
        label_tensor = torch.tensor(label, dtype=torch.int64)

        # Apply model transforms to image
        if self.transform is not None:
            image_t = self.transform(image)
        else:
            image_t = original_tensor

        return {
            "image": image_t,
            "additional_features": additional_features,
            "labels": label_tensor,
            "original": original_tensor,
        }


# --------------------------------------------------
# Main
# --------------------------------------------------

def main():
    # ---------------- Seed ----------------
    seed = 42
    set_global_seed(seed)

    # ---------------- Load features ----------------
    featurestable = pd.read_excel(FEATURES_XLSX)

    # Split as in the notebook: stratify by Class
    subjects_all = list(featurestable["Name"])
    classes_all = list(featurestable["Class"])

    subjects_train, subjects_test = train_test_split(
        subjects_all,
        test_size=0.2,
        random_state=42,
        stratify=classes_all,
    )

    # Rebuild DataFrames for splits
    features_train = featurestable[featurestable["Name"].isin(subjects_train)]
    features_test = featurestable[featurestable["Name"].isin(subjects_test)]

    # Second split: train -> train + val (again stratified)
    train_classes = list(
        features_train.sort_values("Name")["Class"]
    )  # class order by Name
    train_names_sorted = list(features_train.sort_values("Name")["Name"])

    subjects_train_final, subjects_val = train_test_split(
        train_names_sorted,
        test_size=0.2,
        random_state=42,
        stratify=train_classes,
    )

    features_train_final = features_train[features_train["Name"].isin(subjects_train_final)]
    features_val = features_train[features_train["Name"].isin(subjects_val)]

    # ---------------- Datasets & loaders ----------------
    train_loader = DataLoader(
        XAIDataset(subjects=subjects_train_final, features_dataframe=features_train_final, transform=composer),
        batch_size=8,
        shuffle=True,
    )
    val_loader = DataLoader(
        XAIDataset(subjects=subjects_val, features_dataframe=features_val, transform=composer),
        batch_size=8,
        shuffle=True,
    )
    test_loader = DataLoader(
        XAIDataset(subjects=subjects_test, features_dataframe=features_test, transform=composer),
        batch_size=8,
        shuffle=False,
    )

    # ---------------- Rebuild model (same architecture as 3-class model) ----------------
    # CNN output dim: 10 (as in notebook)
    cnn_out_dim = 10
    cnn = ModifiedResNet18(num_classes=cnn_out_dim)

    # Number of additional features from train split
    cols = list(features_train_final.columns)
    n_additional = cols.index("Class") - cols.index("Name") - 1

    mlp_num_layers = 2
    mlp_num_neurons = [8, 3]  # final output: 3 classes

    mlp = MLPModule(
        input_size=cnn_out_dim + n_additional,
        num_layers=mlp_num_layers,
        num_neurons=mlp_num_neurons,
    )

    combined_model = CombinedModel(cnn, mlp).to(device)

    # Load trained weights
    state_dict = torch.load(WEIGHTS_PATH, map_location=device)
    combined_model.load_state_dict(state_dict)
    combined_model.eval()

    # ---------------- Evaluation on test set (confusion matrix) ----------------
    all_preds = []
    all_labels = []
    all_probs = []

    with torch.no_grad():
        for batch in test_loader:
            images = batch["image"].to(device)
            additional_features = batch["additional_features"].to(device)
            labels = batch["labels"].to(device)

            outputs = combined_model(images, additional_features)
            probs = F.softmax(outputs, dim=1)

            preds = torch.argmax(probs, dim=1)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())

    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)
    all_probs = np.array(all_probs)

    cm = confusion_matrix(all_labels, all_preds)
    print("Confusion matrix (trials):")
    print(cm)

    # Optional pretty confusion matrix
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.title("Confusion Matrix (3-class)")
    plt.tight_layout()
    plt.show()

    # ---------------- Integrated Gradients (Captum) ----------------
    # We compute attributions on one batch (as in the notebook)
    first_batch = next(iter(test_loader))
    images = first_batch["image"].to(device)
    additional_features = first_batch["additional_features"].to(device)
    targets = first_batch["labels"].to(device)
    originals = first_batch["original"]  # keep on CPU for plotting

    # Baselines: zeros for image and features
    baseline_images = torch.zeros_like(images).to(device)
    baseline_features = torch.zeros_like(additional_features).to(device)

    ig = IntegratedGradients(combined_model)

    attributions, delta = ig.attribute(
        (images, additional_features),
        baselines=(baseline_images, baseline_features),
        target=targets,  # per-sample target
        method="gausslegendre",
        return_convergence_delta=True,
    )

    # attributions is a tuple: (attr_images, attr_features)
    attr_images = attributions[0].detach().cpu().numpy()
    attr_features = attributions[1].detach().cpu().numpy()

    # Save attributions to disk (as in notebook)
    np.save(ATTRIBUTIONS_OUT, np.stack([attr_images, attr_features], axis=0))
    print(f"Saved attributions to: {ATTRIBUTIONS_OUT}")

    # ---------------- Example visualization ----------------
    # Take one example from the batch (e.g. index 0)
    idx = 0
    selected_original = originals[idx].numpy()
    selected_attr_img = attr_images[idx]

    # Sum channels of attribution to get single heatmap
    heatmap = np.sum(selected_attr_img, axis=0)

    # Plot original image
    plt.figure(figsize=(6, 3))
    plt.subplot(1, 2, 1)
    plt.imshow(selected_original.transpose(1, 2, 0), cmap="gray")
    plt.title(f"Original (class={int(targets[idx])})")
    plt.axis("off")

    # Plot heatmap
    plt.subplot(1, 2, 2)
    plt.imshow(heatmap, cmap="viridis")
    plt.title("IG Attributions (image)")
    plt.axis("off")
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.tight_layout()
    plt.show()

    # Plot feature attributions for the same sample
    feat_attr = attr_features[idx]
    feature_names = cols[cols.index("Name") + 1:cols.index("Class")]

    plt.figure(figsize=(8, 6))
    sns.heatmap(
        feat_attr.reshape(-1, 1),
        annot=True,
        fmt=".3f",
        yticklabels=feature_names,
        xticklabels=["Attribution"],
        cmap="coolwarm",
    )
    plt.title("Integrated Gradients â€“ Feature Attributions")
    plt.tight_layout()
    plt.show()


if __name__ == "__main__":
    main()
